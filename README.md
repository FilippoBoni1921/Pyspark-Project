# Pyspark-Project
In this project parallelized computing is shown to analyze a big amount of data from a particle detector. Pyspark is the main library used to manage the parallelized computing.
Finally a performance analysis is shown to understand the influence of changing some settings on the overall performance of the code.
